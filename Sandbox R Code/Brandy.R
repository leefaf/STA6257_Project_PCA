#library(AER); data(CASchools); View(CASchools)
#library(MASS); data(bacteria); View(bacteria)


library(dplyr)
library(ggplot2)
library(data.table)


# READ & VIEW DATA
conspiracy<- (read.csv("https://raw.githubusercontent.com/bjcarr08/sampleData/main/kaggleConspiracyTheoriesData.csv", stringsAsFactors = T))[,-1]
View(conspiracy)
DescTools::Desc(conspiracy)[[1]]$abstract


# REMOVE ROWS WITH NAs
conspiracy<- conspiracy[complete.cases(conspiracy),]


# STANDARDIZED VARIABLES
conspiracy.Stdz<- conspiracy %>% mutate(across(.cols=truther911:vaportrail, scale))


# LONG DATA
library(tidyr)
conspiracy.Long<- conspiracy %>% pivot_longer(!y, names_to="conspiracy", values_to="score", values_transform=list(score=as.numeric))
conspiracy.Stdz.Long<- conspiracy.Stdz %>% pivot_longer(!y, names_to="conspiracy", values_to="stdzScore", values_transform=list(stdzScore=as.numeric))


# FREQUENCY HISTOGRAMS
ggplot(conspiracy.Long, aes(score, fill=conspiracy, color=conspiracy)) +
  geom_histogram(alpha=0.2, breaks=seq(0,5,1)) +
  lemon::facet_rep_wrap(.~conspiracy, nrow=4, labeller="label_both", repeat.tick.labels=T) +
  labs(title="Raw Scores") +
  theme_bw() +
  theme(legend.position="none")

ggplot(conspiracy.Stdz.Long, aes(stdzScore, fill=conspiracy, color=conspiracy)) +
  geom_histogram(alpha=0.2, breaks=seq(-2,3,1)) +
  lemon::facet_rep_wrap(.~conspiracy, nrow=4, labeller="label_both", repeat.tick.labels=T) +
  labs(title="Standardized Scores") +
  theme_bw() +
  theme(legend.position="none")



#summary(pc.cr <- princomp(conspiracy.Stdz[,-9])) # 1st 2 PCs account for 63% of variance
#loadings(pc.cr)  # blank cells are small, not zero
#biplot(pc.cr, pc.biplot=T, cex=0.6, xpd=T, main="Biplot")
#screeplot(pc.cr, type="lines", col="blueviolet", main="Screeplot")



# PCA
conspiracy<- conspiracy %>% filter(y!="Not Sure") # removed rows where participant marked 'not sure' as political party

yLabs<- c("Very Liberal", "Liberal", "Somewhat Liberal", "Middle of the Road", "Somewhat Conservative", "Conservative", "Very Conservative")

conspiracy$y<- factor(conspiracy$y, ordered=T, levels=yLabs)

#conspiracy %>% count(y)

pca<- princomp(conspiracy[,-9])
PC1<- pca$scores[,1]
PC2<- pca$scores[,2]
PCV1<- pca$loadings[,1]
PCV2<- pca$loadings[,2]
politicalView<- conspiracy[,9]
PCVlabs<- row.names(pca$loadings)

require(grid)

ggplot() +
  geom_point(aes(x=PC1, y=PC2, fill=politicalView), colour='black', pch=21, size=2.5, alpha=0.3) + 
  scale_fill_manual(values=c("navy", "blue", "lightblue1", "white", "indianred1", "red", "red4")) +   
  coord_fixed(ratio=1) +
  geom_segment(aes(x=0, y=0, xend=PCV1*12, yend=PCV2*10), arrow=arrow(length=unit(1/2, 'picas')), color="black") + 
  geom_text(aes(x=PCV1*14, y=PCV2*10), label=PCVlabs, size=4) 


summary(pca)
pca$loadings


################################################################################################
################################################################################################


######### NEW (better) Dataset 
######### CCES 2018 DKU


#### upload file to github instead of reading from local file

DKU<- read.table("C:/Users/b/Downloads/CCES18_DKU_OUTPUT_vv.tab", header=T, sep="\t")

#DKU %>% count(caseid, sort=T) %>% filter(n>1) # check for duplicate respondees

prop.table(ftable(DKU$DKU397, DKU$gender), 2)
prop.table(ftable(DKU$DKU397, DKU$race), 2)

DKU$race2<- ifelse(DKU$race==1, "White", "Not White")
DKU$gender2<- ifelse(DKU$gender==1, "Male", "Female")
DKU$flatEarth<- ifelse(DKU$DKU397==1, "False", 
                       ifelse(DKU$DKU397==2, "Probably False",
                              ifelse(DKU$DKU397==3, "Probably True",
                                     ifelse(DKU$DKU397==4, "True", "Skipped"))))


round(100*(prop.table(ftable(DKU$flatEarth[DKU$flatEarth!="Skipped"], DKU$race2[DKU$flatEarth!="Skipped"]), 2)), 0)

round(100*(prop.table(ftable(DKU$CC18_321f, DKU$gender2), 2)), 0)


DKU %>% count(race)

DKU %>% count(CC18_335)

rowSums(((DKU %>% count(CC18_300d_1,
                        CC18_300d_2,
                        CC18_300d_3,
                        CC18_300d_4,
                        CC18_300d_5))-1)[,-6])


## reduce tax rate for households earning >500k
CC18_325f_new == 1 (support)


### subset using only scale/factor variables -- group PCA analysis by flatearth scaled groups
# rename headers
# remove missing/NA values
# order/level factors
# standardize all vars
# scatter plot first 2 PCs color points based off flatearth group
# analyze loadings between groups


keepHeaders<- c("educ","race","marstat","votereg","region","CC18_301","CC18_302","CC18_316","CC18_335","ownhome","immstat","employ","urbancity","union","internethome","internetwork","sexuality","trans","religpew","DKU312","DKU313","DKU387","DKU391","birthyr","DKU385","DKU386","CC18_308a","CC18_308b","CC18_308c","CC18_308d","CC18_334A","CC18_334D","CC18_334E","CC18_334F","pid3","pid7","pew_religimp","pew_churatd","pew_prayer","ideo5","newsint","faminc_new","DKU305","DKU306","DKU307","DKU308","DKU309","DKU310","DKU311","DKU360","DKU361","DKU362","DKU363","DKU364","DKU373","DKU374","DKU375","DKU376","DKU377","DKU378","DKU379","DKU380","DKU393","DKU394","DKU395","DKU396","DKU397","DKU398")
DKU2<- DKU[,names(DKU) %in% keepHeaders]





################################################################################################
################################################################################################

# UNUSED CODE
# RE-CODE y AS INT
# conspiracy.Int<- conspiracy %>% 
#                    filter(!(y %like% "Other|Sure")) %>% 
#                    mutate(y = ifelse(y=="Very Liberal", 0, 
#                                      ifelse(y=="Liberal", 1,
#                                             ifelse(y=="Somewhat Liberal", 2, 
#                                                    ifelse(y=="Middle of the Road", 3, 
#                                                           ifelse(y=="Somewhat Conservative", 4, 
#                                                                  ifelse(y=="Conservative", 5, 6)))))))
